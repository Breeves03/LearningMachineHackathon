{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9542f5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "%run dataInfo.ipynb\n",
    "%run RandomForest.ipynb\n",
    "\n",
    "cleanTest = test_df\n",
    "cleanTrain = train_df #doesn't have asd/class\n",
    "\n",
    "# Drop train class column\n",
    "cleanTrain = cleanTrain.drop(columns=['Class/ASD'])\n",
    "cleanTest = cleanTest.drop(columns=['Class/ASD'])\n",
    "cleanTrain = cleanTrain.drop(columns=['country_of_res'])\n",
    "cleanTest = cleanTest.drop(columns=['country_of_res'])\n",
    "cleanTrain = cleanTrain.drop(columns=['relation'])\n",
    "cleanTest = cleanTest.drop(columns=['relation'])\n",
    "\n",
    "# Combine train and test data for preprocessing\n",
    "combined_df = pd.concat([cleanTrain, cleanTest], axis=0)\n",
    "combined = combined_df.dropna()\n",
    "\n",
    "#Engineer Composite Features\n",
    "\n",
    "# Create a new feature 'mean_A_score' by averaging the scores of A1 to A10\n",
    "score_cols = [f\"A{i}_Score\" for i in range(1, 11)]\n",
    "combined['mean_A_score'] = combined[score_cols].mean(axis=1)\n",
    "\n",
    "# score times age\n",
    "combined['age_x_mean_A'] = combined['age'] * combined['mean_A_score']\n",
    "\n",
    "# Polynomial features (squared terms)\n",
    "combined['age_squared'] = combined['age'] ** 2\n",
    "combined['mean_A_score_squared'] = combined['mean_A_score'] ** 2\n",
    "\n",
    "#dont use scaler bc it makes it worse\n",
    "\n",
    "# run the hierarchical clustering\n",
    "model = AgglomerativeClustering(n_clusters=2, linkage='ward')  # Choose the number of clusters you want (e.g., 3)\n",
    "combined['hierarchical_cluster'] = model.fit_predict(combined)\n",
    "hierarchical_siloutte = silhouette_score(combined, combined['hierarchical_cluster'])\n",
    "print(f\"Silhouette Score for Hierarchical Clustering: {hierarchical_siloutte}\")\n",
    "db_hierarchical = davies_bouldin_score(combined, combined['hierarchical_cluster'])\n",
    "print(f\"Davies-Bouldin Score for Hierarchical Clustering: {db_hierarchical}\")\n",
    "\n",
    "combined['hierarchical_cluster'] = combined['hierarchical_cluster']\n",
    "\n",
    "cluster_summary = combined.groupby('hierarchical_cluster').mean()\n",
    "\n",
    "#Print cluster summaries\n",
    "print(\"Hierarchical Cluster Summary:\")\n",
    "print(cluster_summary)\n",
    "\n",
    "# Reduce dimensionality\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(combined.drop(columns=['kmeans_cluster', 'gmm_cluster']))\n",
    "\n",
    "# Convert to DataFrame\n",
    "pca_df = pd.DataFrame(reduced_data, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Add cluster labels to PCA DataFrame\n",
    "pca_df['hierarchical_cluster'] = combined['hierarchical_cluster'].values\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
