{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73c62b8",
   "metadata": {},
   "source": [
    "# Counterfactual Fairness Analysis\n",
    "\n",
    "This notebook evaluates counterfactual fairness by swapping sensitive attributes (gender or ethnicity) while keeping AQ-10 answers fixed. The change in predicted probabilities (Δ probability) is recorded using the all supervised models. This analysis helps in understanding the fairness of the model with respect to sensitive attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f627956c",
   "metadata": {},
   "source": [
    "# Counterfactual Fairness Analysis Function\n",
    "\n",
    "The `counterfactual_fairness_analysis` function evaluates the fairness of a model by swapping sensitive attributes (e.g., gender or ethnicity) and measuring the change in predicted probabilities. It returns a DataFrame containing the original and swapped probabilities along with their differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45b246ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counterfactual_fairness_analysis(data, model, sensitive_column, fixed_columns):\n",
    "    results = []\n",
    "    for index, row in data.iterrows():\n",
    "        X_original = pd.DataFrame([row.drop(fixed_columns)])\n",
    "        X_original = X_original.reindex(columns=model.feature_names_in_, fill_value=0)\n",
    "        original_prob = model.predict_proba(X_original)[:, 1][0]\n",
    "\n",
    "\n",
    "        # Swap sensitive attribute\n",
    "        if sensitive_column == 'gender':\n",
    "            row[sensitive_column] = 1 - row[sensitive_column]  # Swap gender\n",
    "        elif sensitive_column == 'ethnicity':\n",
    "            for col in row.index:\n",
    "                if col.startswith('ethnicity_') and row[col] == 1:\n",
    "                    row[col] = 0\n",
    "                elif col.startswith('ethnicity_') and row[col] == 0:\n",
    "                    row[col] = 1\n",
    "                    break\n",
    "\n",
    "\n",
    "        X_swapped = pd.DataFrame([row.drop(fixed_columns)])\n",
    "        X_swapped = X_swapped.reindex(columns=model.feature_names_in_, fill_value=0)\n",
    "        swapped_prob = model.predict_proba(X_swapped)[:, 1][0]\n",
    "\n",
    "        delta_prob = swapped_prob - original_prob\n",
    "\n",
    "        results.append({\n",
    "            'Index': index,\n",
    "            'Original_Probability': original_prob,\n",
    "            'Swapped_Probability': swapped_prob,\n",
    "            'Delta_Probability': delta_prob\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ebfe94",
   "metadata": {},
   "source": [
    "# Test Model Function\n",
    "\n",
    "The `testModel` function performs counterfactual fairness analysis for both gender and ethnicity. It calculates the mean change in probabilities (Δ probability) for each sensitive attribute and prints the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f9f06f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model, test_df):\n",
    "    # Perform counterfactual fairness analysis for gender\n",
    "    sensitive_column = 'gender'\n",
    "    fixed_columns = [col for col in test_df.columns if col != 'gender' and not col.startswith('ethnicity')]\n",
    "\n",
    "    results_gender = counterfactual_fairness_analysis(cleanTest, rf_model, sensitive_column, fixed_columns)\n",
    "    print(results_gender) \n",
    "\n",
    "    # Perform counterfactual fairness analysis for ethnicity\n",
    "    sensitive_column = 'ethnicity'\n",
    "\n",
    "    results_ethnicity = counterfactual_fairness_analysis(cleanTest, rf_model, sensitive_column, fixed_columns)\n",
    "    print(results_ethnicity)\n",
    "\n",
    "    # Calculate mean delta probabilities\n",
    "    mean_delta_gender = results_gender['Delta_Probability'].mean()\n",
    "    mean_delta_ethnicity = results_ethnicity['Delta_Probability'].mean()\n",
    "\n",
    "    print(f\"Mean Delta Probability for Gender: {mean_delta_gender}\")\n",
    "    print(f\"Mean Delta Probability for Ethnicity: {mean_delta_ethnicity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf37dd",
   "metadata": {},
   "source": [
    "# Random Forest Model Testing\n",
    "\n",
    "This section loads the Random Forest model from the `SupervisedRandomForest` notebook and performs counterfactual fairness analysis using the `testModel` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72caaf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Random Forest model \n",
    "%run SupervisedRandomForest.ipynb\n",
    "testModel(rf_model, cleanTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee437801",
   "metadata": {},
   "source": [
    "# CatBoost Model Testing\n",
    "\n",
    "This section loads the CatBoost model from the `SupervisedCatBoost` notebook and performs counterfactual fairness analysis using the `testModel` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463b2594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Cat Boost model \n",
    "%run SupervisedCatBoost.ipynb\n",
    "testModel(catboost_model, cleanTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a73ae",
   "metadata": {},
   "source": [
    "# XGBoost Model Testing\n",
    "\n",
    "This section loads the XGBoost model from the `SupervisedXGBoost` notebook and performs counterfactual fairness analysis using the `testModel` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef46273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the XG Boost model \n",
    "%run SupervisedXGBoost.ipynb\n",
    "testModel(xgb_model, cleanTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb32833",
   "metadata": {},
   "source": [
    "# Logistic Regression Model Testing\n",
    "\n",
    "This section loads the Logistic Regression model from the `SupervisedLogisticRegression` notebook and performs counterfactual fairness analysis using the `testModel` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad82ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Logistic Regression model \n",
    "%run SupervisedlogisticRegression.ipynb\n",
    "testModel(model, cleanTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
